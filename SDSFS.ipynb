{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:Red\"><font size=\"5\">Stochastic Diffusion Search</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p ><font size=\"3\">SDS is an agent-based algorithm that can be used in a variety of contexts to solve different problems. We will be using a flavor of SDS to solve the problem of \"curse of dimensionality\" in the datasets. I recommend you to read this intuitive <a href=\"http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification\">article</a> on curse of  dimensionality and its repercussions</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p ><font size=\"3\"> The theory behind the algorithm that I coded below is originally published <a href=\"https://dl.acm.org/citation.cfm?id=3079193\">here</a>. I strongle recommend to give a read before trying the algorithm. However, I made some key improvements to the original algorithm</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating instances of estimators\n",
    "logReg=LogisticRegression(C=2)\n",
    "decClf=DecisionTreeClassifier(max_depth=5, min_samples_split=4)\n",
    "svc=SVC(C=0.5,gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators=[svc,logReg,decClf] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Below function returns an agent, which is hypothesis, and its corresponding binary array.\n",
    "1 indicates inclusion of corresponding feature and 0 indicates exclusion of the feature.\n",
    "lowerLim indicates minimum number of features, whereas; upperLim indicated max no of features to beincluded in an agent.\n",
    "'''\n",
    "def agent(arryX,lowerLim,upperLim):\n",
    "        if lowerLim<0 or upperLim>arryX.shape[1]:\n",
    "            print('recall function with appropriate limits')\n",
    "        else:\n",
    "            randomNoFeatures=np.random.randint(lowerLim,upperLim,size=1)[0] #generating a random number\n",
    "            zeroArry=np.zeros(arryX.shape[1]-randomNoFeatures, dtype='int') #zero array \n",
    "            oneArry=np.ones(randomNoFeatures, dtype='int')   #one array\n",
    "            fArry=np.concatenate((zeroArry,oneArry), axis=0) #concatinating zero and one array\n",
    "            np.random.shuffle(fArry) #shuffling fArray\n",
    "            fIndex=np.where(fArry==1)[0]\n",
    "            agentArry=arryX[:,fIndex] #generating feature subset from origanal dataset\n",
    "            return fArry,agentArry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Below function generates required number of agents that are to be deployed on search space. \n",
    "All the agents and corresponding binary feature array are stored and returned as a list.\n",
    "'''\n",
    "def agentsInitiation(arryX,numAgents,lowerLim,upperLim):\n",
    "        agents=[]\n",
    "        agentFIndex=[]\n",
    "        agentStatus=['active']*numAgents\n",
    "        for i in range(0,numAgents):\n",
    "            fArry,agentArry=agent(arryX,lowerLim,upperLim) #generating a single agent\n",
    "            agentFIndex.append(fArry) #appending its binary feature array to agentFIndex\n",
    "            agents.append(agentArry) #appending the agent to the agents list\n",
    "        return agents,agentFIndex,agentStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "'Score' function fits each model to the agent's training data and then evaluates the score on test agent. \n",
    "The output is the average score of three estimators. Original paper used only one classifier to calculate score.\n",
    "Therefore, the resultant subset was very biased towards the signle estimator. \n",
    "To avoind this, we are using ensemble of classifiers.\n",
    "'''\n",
    "def score(estimators,arryX,arrY):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(arryX,arrY,random_state=0)\n",
    "        scores=[]\n",
    "        for i in range(len(estimators)):\n",
    "            estimators[i].fit(X_train,y_train) #fitting the ith estimator to the training data of an agent\n",
    "            scores.append(estimators[i].score(X_test,y_test)) #evaluating the score on the test data\n",
    "        return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below function calculates score for each agents and appends the score to the agentScores list\n",
    "def agentClfscores(estimators,agents,arrY):\n",
    "    agentScores=[]\n",
    "    for agent in agents:\n",
    "        agentscore=score(estimators,agent,arrY)\n",
    "        agentScores.append(agentScores)\n",
    "    return agentScores #returns a list that caputres agents' scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Below function carries out test and diffusion phase among the agents initialized above. \n",
    "The function returns agents and their corresponding scores, binary feature arrays, and staus after numIterations.\n",
    "'''\n",
    "\n",
    "def SDSFS(arryX,arrY,estimators,numIterations,numAgents,lowerLim,upperLim):\n",
    "    agents,agentFIndex,agentStatus=agentsInitiation(arryX,numAgents,lowerLim,upperLim)\n",
    "    agentScores=agentClfscores(estimators,agents,arrY)\n",
    "    niters=0\n",
    "    while niters<numIterations:\n",
    "        #testing phase\n",
    "        for i in range(len(agents)):\n",
    "            rndmId=np.random.randint(len(agents),size=1)[0]\n",
    "            if agentScores[i]>agentScores[rndmId]:\n",
    "                agentStatus[i]='active' \n",
    "                \n",
    "            else:\n",
    "                agentStatus[i]='inactive'\n",
    "                \n",
    "        #Diffusion phase    \n",
    "        for i in range(len(agents)):\n",
    "                if agentStatus[i]=='inactive':\n",
    "                    rndmId2=np.random.randint(len(agents),size=1)[0]\n",
    "                    if agentStatus[rndmId2]=='active':\n",
    "                        oneIds=np.where(agentFIndex[rndmId2]==1)[0]\n",
    "                        zeroIds=np.where(agentFIndex[rndmId2]==0)[0]\n",
    "                        rndmId3=np.random.randint(len(oneIds), size=1)\n",
    "                        rndmId4=np.random.randint(len(zeroIds), size=1)\n",
    "                        oneZeroId=oneIds[rndmId3]\n",
    "                        zeroOneId=zeroIds[rndmId4]\n",
    "                        agentFIndex[i]=agentFIndex[rndmId2].copy()\n",
    "                        agentFIndex[i][oneZeroId]=0\n",
    "                        agentFIndex[i][zeroOneId]=1\n",
    "                        fIndex2=np.where(agentFIndex[i]==1)[0]\n",
    "                        agents[i]=X[:,fIndex2]\n",
    "                        agentScores[i]=score(estimators,agents[i],arrY)\n",
    "                    else:\n",
    "                        agentFIndex[i],agents[i]=agent(arryX,lowerLim,upperLim)\n",
    "                        agentScores[i]=score(estimators,agents[i],arrY)\n",
    "                else:\n",
    "                    rndmId5=np.random.randint(len(agents),size=1)[0]\n",
    "                    if agentStatus[rndmId5]=='active' and (agentFIndex[i]==agentFIndex[rndmId5]).all():\n",
    "                        agentStatus[i]='inactive'\n",
    "                        agentFIndex[i],agents[i]=agent(arryX,lowerLim,upperLim)\n",
    "                        agentScores[i]=score(estimators,agents[i],arrY)\n",
    "        niters+=1\n",
    "    return agents,agentFIndex,agentStatus,agentScores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p style=\"color:Red\"><font size=\"5\">Testing SDSFS on a dataset</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. \n",
    "It contains 97 patterns obtained from rocks under similar conditions. \n",
    "The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. \n",
    "The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('files/Sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #the dataset has 60 features and one class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      V10  ...       V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.2111  ...    0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...    0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...    0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...    0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...    0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      1  \n",
       "1  0.0052  0.0044      1  \n",
       "2  0.0095  0.0078      1  \n",
       "3  0.0040  0.0117      1  \n",
       "4  0.0107  0.0094      1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111\n",
       "1     97\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts() #the dataset has 111 class 0 instances and 97 class 1 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) #deleting any rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().isnull().any() #confirming there are no missing values in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array(df[list(df.columns[:-1])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train,y_train) #fitting Logistic Regression on Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "logReg_score=logReg.score(X_test,y_test) #Test score\n",
    "print(logReg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train) #fitting Support Vector Machines to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826923076923\n"
     ]
    }
   ],
   "source": [
    "svc_score=svc.score(X_test,y_test)\n",
    "print(svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decClf.fit(X_train,y_train) #fitting decision tree classifer to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.769230769231\n"
     ]
    }
   ],
   "source": [
    "decClf_score=decClf.score(X_test,y_test)\n",
    "print(decClf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to run SDSFS algorithm to check if it can improve the accuracy of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents,agentFIndex,agentStatus,agentScores=SDSFS(X,y,estimators,150,120,5,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87820512820512819"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(agentScores) #one of the agents achieved an accuracy of 86.5 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.array(agentScores)) #agent 29 scored achieved the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 24)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents[36].shape #the agent that scored 86.5% accuracy as just 24 features against 60 features in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the models on this agent instead of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(agents[36],y, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884615384615\n"
     ]
    }
   ],
   "source": [
    "logReg_score2=logReg.score(X_test,y_test) #accuracy improved from 75 to 88\n",
    "print(logReg_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846153846154\n"
     ]
    }
   ],
   "source": [
    "svc_score2=svc.score(X_test,y_test) #accuracy increased by 2 percent\n",
    "print(svc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decClf.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865384615385\n"
     ]
    }
   ],
   "source": [
    "decClf_score2=decClf.score(X_test,y_test) #accuracy increased by 10 percent\n",
    "print(decClf_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame([[logReg_score,svc_score,decClf_score],[logReg_score2,svc_score2,decClf_score2]], columns=['Logistic Regression','SVM','Decision Tree'], index=['original dataset','SDSFS subset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original dataset</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDSFS subset</th>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.865385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Logistic Regression       SVM  Decision Tree\n",
       "original dataset             0.750000  0.826923       0.769231\n",
       "SDSFS subset                 0.884615  0.846154       0.865385"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy improved for all the models with the subset obtained from SDSFS algorithm. I'm still trying to improve the algorithm to get more consistent and reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
